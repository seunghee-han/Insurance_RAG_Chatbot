{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a510da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./kb_pdf/24734_2_1.pdf' 파일을 로드 중...\n",
      "'./kb_pdf/KB_Direct_MotoDrivr(24763)_202504.pdf' 파일을 로드 중...\n",
      "'./kb_pdf/KB_Direct_ShtrDrivr(15506)_202506.pdf' 파일을 로드 중...\n",
      "'./kb_pdf/KB_Direct_LngtrmDriver(24755)_202508.pdf' 파일을 로드 중...\n",
      "총 12867개의 문서 조각이 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_postgres import PGVector\n",
    "\n",
    "connection_string = \"postgresql+psycopg2://play:123@192.168.0.22:5432/team3\"\n",
    "\n",
    "collection_name = 'kb'\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from glob import glob\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "# 1) 임베딩/LLM\n",
    "embedding = OpenAIEmbeddings()  # 모델 생략 시 기본(text-embedding-3-large 계열)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 2) PDF 로드\n",
    "pdf_files = glob(\"./kb_pdf/*.pdf\")\n",
    "documents = []\n",
    "\n",
    "# 의미 단락 + 길이 상한 병행(권장)\n",
    "semantic_splitter = SemanticChunker(\n",
    "    OpenAIEmbeddings(),\n",
    "    breakpoint_threshold_type=\"percentile\",\n",
    "    breakpoint_threshold_amount=50,\n",
    ")\n",
    "fallback_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200, chunk_overlap=150, separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    try:\n",
    "        print(f\"'{pdf_file}' 파일을 로드 중...\")\n",
    "        loader = PyPDFLoader(pdf_file)\n",
    "        docs = loader.load()  # 각 페이지가 Document, metadata에 source/page 포함\n",
    "\n",
    "        # 2단 분할: 의미 분할 → 너무 긴 chunk는 문자 분할로 재분절\n",
    "        sem_chunks = semantic_splitter.split_documents(docs)\n",
    "        chunks = []\n",
    "        for d in sem_chunks:\n",
    "            if len(d.page_content) > 1600:\n",
    "                chunks.extend(fallback_splitter.split_documents([d]))\n",
    "            else:\n",
    "                chunks.append(d)\n",
    "\n",
    "        documents.extend(chunks)\n",
    "    except Exception as e:\n",
    "        print(f\"'{pdf_file}' 파일 로드 중 오류 발생: {e}\")\n",
    "\n",
    "if not documents:\n",
    "    print(\"PDF 파일이 없거나 로드에 실패했습니다..\")\n",
    "else:\n",
    "    print(f\"총 {len(documents)}개의 문서 조각이 생성되었습니다.\")\n",
    "\n",
    "# 3) 벡터스토어 생성/초기화\n",
    "vectorstore = PGVector(\n",
    "    embeddings=embedding,\n",
    "    collection_name=collection_name,\n",
    "    connection=connection_string,\n",
    "    use_jsonb=True,\n",
    "    # pre_delete_collection=True  # 매번 새로 구축\n",
    ")\n",
    "\n",
    "# 4) 색인\n",
    "if documents:\n",
    "    vectorstore.add_documents(documents)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
