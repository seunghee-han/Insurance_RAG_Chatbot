{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a7ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time, uuid\n",
    "from typing import List, Dict\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_postgres import PGVector\n",
    "from langchain.retrievers import EnsembleRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c993a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 사용자 설정 =========\n",
    "INPUT_JSONL  = \"./eval_driver_insurance.jsonl\"   # 기존 데이터셋\n",
    "OUTPUT_JSONL = \"./eval_driver_insurance_rebuilt.jsonl\"  # 결과 파일\n",
    "REWRITE_CONTEXTS = True       # 컨텍스트도 새로 검색해 갈아끼우기 여부\n",
    "K = 3                         # 검색 문서 k\n",
    "MODEL = \"gpt-4o-mini\"         # LLM 모델\n",
    "TEMP  = 0.1                   # LLM temperature\n",
    "MAX_TOKENS = 1500\n",
    "RATE_LIMIT_SLEEP = 0.8        # 과한 호출 방지용 딜레이(초)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf86111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== 벡터DB/리트리버 연결 ========\n",
    "connection_string = \"postgresql+psycopg2://play:123@192.168.0.8:5432/team3\"\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "collection_names = ['DB', 'samsung', 'hanwha', \"현대해상\", \"test\", \"meritzfire\"]\n",
    "retrievers = []\n",
    "for name in collection_names:\n",
    "    vectorstore = PGVector(\n",
    "        embeddings=embedding,\n",
    "        collection_name=name,\n",
    "        connection=connection_string,\n",
    "        use_jsonb=True\n",
    "    )\n",
    "    retrievers.append(vectorstore.as_retriever(search_kwargs={'k': K}))\n",
    "\n",
    "combined_retriever = EnsembleRetriever(retrievers=retrievers)\n",
    "\n",
    "# ======== LLM & 프롬프트 ========\n",
    "# ※ 프롬프트는 원하시는 대로 자유롭게 바꾸시면 됩니다.\n",
    "template_dw =   \"\"\"당신은 여러 보험사의 상품을 비교 분석하여 사용자에게 가장 쉽고 친절하게 정보를 전달하는 보험 전문가 챗봇입니다.\n",
    "\n",
    "다음 지시사항을 철저히 따라 사용자의 질문에 한국어로 답변하세요.\n",
    "\n",
    "답변의 서식:\n",
    "마크다운(Markdown)을 사용하여 답변을 구조화하세요.\n",
    "줄바꿈은 최대 두 칸만 사용하세요.\n",
    "주요 정보는 볼드체로 강조하세요.\n",
    "\n",
    "모든 섹션은 반드시 아래 계층을 따릅니다.\n",
    "1) 제목: ##  (한 답변에 2~4개 이하 권장)\n",
    "2) 소제목: ###  (상품명/항목명/소단락 제목은 반드시 소제목으로, 불릿 금지)\n",
    "3) 세부 포인트: -  불릿 목록 (각 소제목 아래 설명은 모두 불릿으로 정리)\n",
    "불릿은 “- ” + 공백 + 텍스트 형식만 사용합니다.\n",
    "헤딩 앞뒤 빈 줄은 딱 1줄만, 불릿 사이에는 빈 줄 금지.\n",
    "\n",
    "여러 회사를 비교하는 경우, 반드시 마크다운 표를 활용하여 설명과 함께 항목별로 정리하세요.\n",
    "표를 만들 때는 필요시 '추천도' 열을 포함하세요.\n",
    "추천도 열에만 ⭕ / ▲ / ○(보통) / × / - 다섯 가지 기호만 사용하세요.\n",
    "추천도 열 사용시, 표 바로 아래줄에 반드시 범례를 추가하세요: ⭕ 강력 추천 / ▲ 조건부 / ○ 보통 / × 없음 / - 미확인\n",
    "\n",
    "\n",
    "답변의 내용:\n",
    "전문 용어는 피하고, 누구나 이해할 수 있도록 쉽고 자세하게 설명하세요.\n",
    "답변은 질문에 대한 직접적인 내용만을 포함하며, 불필요한 서론이나 결론은 제외하세요.\n",
    "제시된 '컨텍스트' 내의 정보만 사용하세요. 컨텍스트에 없는 내용은 절대로 지어내지 마세요.\n",
    "컨텍스트에 없는 내용을 질문할 시, 모른다고 말하지말고 질문한 회사의 전화번호나 링크를 줘서 직접 내용을 탐색하도록 유도하세요.\n",
    "비교할때는 차이점을 명확하게 구체적으로 설명하세요.\n",
    "추천 시에는 그 이유(보장 범위, 특화 옵션, 지급 조건 등)를 구체적으로 설명하세요.\n",
    "사용자 상황(사고 유형/과실/연령 등)을 반영해 차이점·추천 근거를 구체적으로 제시.\n",
    "\n",
    "출처 표기:\n",
    "답변에 사용된 모든 정보는 마지막에 출처(파일명/페이지)를 명확히 명시하세요.\n",
    "출처는 항상 괄호(()) 안에 (출처: 파일명, 페이지 p.N) 형식으로 표시하세요.\n",
    "\n",
    "마지막에는 항상 더 물어볼 내용이 있는지 물어보면서 대화를 더 길게하도록 유도해\n",
    "\n",
    "[대화 기록]\n",
    "{history}\n",
    "\n",
    "[질문]\n",
    "{question}\n",
    "\n",
    "[컨텍스트]\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt_dowon = ChatPromptTemplate.from_template(template_dw)\n",
    "\n",
    "llm = ChatOpenAI(model=MODEL, temperature=TEMP, max_tokens=MAX_TOKENS)\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": RunnablePassthrough(),  # 컨텍스트는 바깥에서 준비해 주입\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt_dowon\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ======== 유틸 함수들 ========\n",
    "def format_docs_for_prompt(docs: List[Document]) -> str:\n",
    "    \"\"\"프롬프트 주입용: 본문 + (파일명/페이지) 라벨 포함\"\"\"\n",
    "    chunks = []\n",
    "    source_map = {}\n",
    "    counter = 1\n",
    "    for d in docs:\n",
    "        src = d.metadata.get(\"source\", \"알 수 없는 출처\")\n",
    "        page = d.metadata.get(\"page\", None)\n",
    "        if isinstance(page, int):\n",
    "            page_disp = page + 1\n",
    "        else:\n",
    "            page_disp = page or \"?\"\n",
    "        if src not in source_map:\n",
    "            source_map[src] = counter\n",
    "            counter += 1\n",
    "        doc_id = source_map[src]\n",
    "        base = os.path.basename(src)\n",
    "        chunks.append(f\"[문서 {doc_id} - {base}, 페이지 {page_disp}]\\n{d.page_content}\\n\")\n",
    "    return \"\\n\".join(chunks)\n",
    "\n",
    "def docs_to_context_list(docs: List[Document], max_chars: int = 1200) -> List[str]:\n",
    "    \"\"\"데이터셋 저장용: contexts 필드(List[str])에 넣을 적당한 길이의 청크\"\"\"\n",
    "    out = []\n",
    "    for d in docs:\n",
    "        src = d.metadata.get(\"source\", \"unknown\")\n",
    "        page = d.metadata.get(\"page\", None)\n",
    "        page_disp = page + 1 if isinstance(page, int) else page or \"?\"\n",
    "        head = f\"[{os.path.basename(src)} p.{page_disp}] \"\n",
    "        text = (d.page_content or \"\").strip()\n",
    "        # 너무 긴 경우 잘라서 저장\n",
    "        clipped = (text[:max_chars] + \"…\") if len(text) > max_chars else text\n",
    "        out.append(head + clipped)\n",
    "    return out\n",
    "\n",
    "def retrieve_contexts(question: str, k: int = K) -> List[Document]:\n",
    "    return combined_retriever.get_relevant_documents(question)\n",
    "\n",
    "def load_jsonl(path: str) -> List[Dict]:\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or not line.startswith(\"{\"):\n",
    "                continue\n",
    "            try:\n",
    "                rows.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                # 만약 }{ 형태로 붙어있는 라인이 있다면 보정 시도\n",
    "                try:\n",
    "                    fixed = \"[\" + line.replace(\"}\\n{\", \"},{\") + \"]\"\n",
    "                    rows.extend(json.loads(fixed))\n",
    "                except Exception:\n",
    "                    pass\n",
    "    return rows\n",
    "\n",
    "def save_jsonl(rows: List[Dict], path: str):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for r in rows:\n",
    "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f07158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 샘플 수: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54681/4248642854.py:117: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  return combined_retriever.get_relevant_documents(question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진행 5/30\n",
      "진행 10/30\n",
      "진행 15/30\n",
      "진행 20/30\n",
      "진행 25/30\n",
      "진행 30/30\n",
      "['[무배당 삼성화재 운전자보험 안전운전 파트너 플러스(2504.8) 1종(연만기, 납입면제형).pdf p.460] 외상성 상부관절와순 파열로 수술을 시행한 상해 \\n10. 어깨관절 탈구로 수술을 시행한 상해 \\n11. 어깨관절의 골절 및 탈구로 수술을 시행하지 않은 상해 \\n12. 위팔뼈 대결절 견열 골절 \\n13. 위팔뼈 먼쪽 부위 견열골절(외상과 골절, 내상과 골절 등에 해당한다) \\n14. 팔꿈치관절 부위 골절 및 탈구로 수술을 시행하지 않은 상해 \\n15.', '[한화 운전자상해보험 무배당 2504.pdf p.258] 경찰서에서 발행한 교통사고사실확인원3. 경찰서 또는 검찰청에 제출된 자동차 교통사고 형사합의서(단, 합의금액이 명시되어 있어야 하며, 합의금액을 장래에 지급한다는 내용이 포함되어 있어야 합니다)4. 검찰에 의해 기소된 경우 검찰청에서 발행한 공소장5.', '[DB운전자보험.pdf p.42] - 경찰서에 제출된 형사합의서(합의금액 명시)\\n- 피해자 공탁금 출금 확인서(미합의시) 및\\n  공탁서\\n- 경찰서/법원\\n- 법원\\n- 법원', '[현대해상약관.pdf p.26] 방어비용 - 공소 제기시(약식기소 포함)   ① 교통사고사실확인원   ② 약식명령문 또는 법원 판결문경찰서법원 - 구속시   ① 구속영장 또는 사건처분증명원   ② 재소 또는 출소증명원법원구치소변호사선임비용 - 교통사고사실확인원 - 판결문, 공소장, 변호사가 발행한 세금계산서 - 구속영장 또는 사건처분증명원 - 재소 또는 출소증명원경찰서/법원구치소변호사사무소면허정지/취소위로금 - 교통사고사실확인원 - 운전경력증명서 - 면허정지확인원(교육 이수 후) - 면허취소확인원경찰서★ 당사 자동차보험 가입자는 별도 서류 없이 당사에서 확인 가능합니다.', '[unknown p.?] 한국의 수도는 서울입니다.', '[메리츠 운전자 상해 종합보험.pdf p.429] 경골하 3분의 1부 분쇄성골절9. 3도화상등 연주조직손상이 체표의 약 9퍼센트 이상인 상해10.', '[DB운전자보험.pdf p.634] 는 그 권리를 지키거나 행사하기 위하여 지출한 필요 또는 유익하였던 비용\\n㉰ 피보험자가 지급한 소송비용, 변호사비용, 중재, 화해 또는 조정에 관한 비용\\n㉱ 보험증권상의 보상한도액내의 금액에 대한 공탁보증보험료. 그러나 회사는 \\n그러한 보증을 제공할 책임은 부담하지 않습니다.\\n㉲ 피보험자가 13.(손해배상청구에 대한 회사의 해결) \\n\\U000f02b2 및 \\U000f02b3의 회사의 요구\\n에 따르기 위하여 지출한 비용', '[현대해상약관.pdf p.277] 시행령 제3조에서 정한 상해등급 1급, 2급 또는 3급에 해당하는 부상을 입힌 혐의로 경찰조사 후 불송치된 경우, 검찰에 의해 약식기소 또는 불기소된 경우변호사선임비용(제4항에 따른 금액한도 이내)  ② 제1항 제1호 내지 제4호의 변호사선임비용은 1사고마다 각 호의 금액을 한도로 지급합니다', '[unknown p.?] LangChain은 LLM을 활용한 애플리케이션 개발을 돕는 프레임워크입니다.', '[메리츠 운전자 상해 종합보험.pdf p.423] 수장부 근건 파열창(상완심부 열창으로 삼각근, 이두근 근건파열을 포함한다)10.', '[DB운전자보험.pdf p.433] 시되어 있어야 합니다.)\\n③ 검찰에 의해 기소된 경우 검찰청에서 발행한 공소장\\n④ 법원 혹은 검찰청에 제출된 공탁서 및 피해자의 공탁금 출급 확인서 \\n⑤ 기타 보험회사가 필요하다고 인정하는 서류\\n\\U000f02b6 위 \\U000f02b4에 따라 보험회사가 형사합의금을 피해자에게 직접 지급할 경우 피보험자는 \\n다음의 서류를 제출하여야 합니다.', '[현대해상약관.pdf p.52] 자동차사고변호사선임비용Ⅲ(중상해경찰조사)일반교통사고로 타인에게 자동차손해배상보장법 시행령 제3조에서 정한 상해1~3급에 해당하는 부상을 입힌 혐의로 경찰 조사 후 불송치된 경우, 검찰에 의해 약식기소 또는 불기소된 경우1사고당 보험증권에 기재된 금액을 한도로 변호사선임비용으로 부담한 금액을 실손보상함', '[unknown p.?] RAG는 Retrieval-Augmented Generation의 약자입니다.', '[메리츠 운전자 상해 종합보험.pdf p.423] 슬관절부의 내ㆍ외측부 인대, 전ㆍ후십자 인대, 내ㆍ외측반월상 연골 완전 파열(부분 파열로 수술을 시행한 경우를 포함한다)12. 관혈적 정복술을 시행한 소아의 경ㆍ비골 아래 3분의 1 이상의 분쇄성 골절13.']\n",
      "완료: ./eval_driver_insurance_rebuilt.jsonl 샘플 수: 30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ======== 본 작업 파이프라인 ========\n",
    "dataset = load_jsonl(INPUT_JSONL)\n",
    "print(f\"입력 샘플 수: {len(dataset)}\")\n",
    "\n",
    "rebuilt = []\n",
    "for i, row in enumerate(dataset, 1):\n",
    "    q = row.get(\"question\", \"\").strip()\n",
    "    if not q:\n",
    "        continue\n",
    "\n",
    "    # 컨텍스트 새로 뽑기 또는 기존 유지\n",
    "    if REWRITE_CONTEXTS:\n",
    "        docs = retrieve_contexts(q)\n",
    "        ctx_for_prompt = format_docs_for_prompt(docs)\n",
    "        ctx_for_json = docs_to_context_list(docs)\n",
    "    else:\n",
    "        # 기존 contexts를 프롬프트에 주입 가능한 문자열로 변환\n",
    "        old_ctx_list = row.get(\"contexts\", []) or []\n",
    "        ctx_for_prompt = \"\\n\".join(f\"[컨텍스트 {idx+1}]\\n{c}\\n\" for idx, c in enumerate(old_ctx_list))\n",
    "        ctx_for_json = old_ctx_list\n",
    "\n",
    "    # LLM으로 새 answer 생성\n",
    "    try:\n",
    "        answer = chain.invoke({\"question\": q, \"context\": ctx_for_prompt})\n",
    "    except Exception as e:\n",
    "        # 실패 시 빈 문자열로 남기고 계속 진행\n",
    "        answer = f\"(생성 실패: {e})\"\n",
    "\n",
    "    # 결과 레코드 구성: id/timestamp/ground_truth 등은 원본 유지\n",
    "    new_row = dict(row)\n",
    "    new_row[\"answer\"] = answer\n",
    "    new_row[\"contexts\"] = ctx_for_json\n",
    "    # 필요 시 prompt 버전 표시(옵션)\n",
    "    new_row[\"prompt_version\"] = \"template_dw.v2\"\n",
    "\n",
    "    rebuilt.append(new_row)\n",
    "\n",
    "    if i % 5 == 0:\n",
    "        print(f\"진행 {i}/{len(dataset)}\")\n",
    "    time.sleep(RATE_LIMIT_SLEEP)\n",
    "\n",
    "\n",
    "print(ctx_for_json)\n",
    "\n",
    "save_jsonl(rebuilt, OUTPUT_JSONL)\n",
    "print(\"완료:\", OUTPUT_JSONL, \"샘플 수:\", len(rebuilt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e07351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os, json, time\n",
    "from typing import List, Dict\n",
    "from datasets import Dataset\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_postgres import PGVector\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "# =========================\n",
    "# 사용자 설정\n",
    "# =========================\n",
    "INPUT_JSONL  = \"./eval_driver_insurance.jsonl\"  # 기존 jsonl 파일 경로\n",
    "REWRITE_CONTEXTS = True      # True: retriever로 contexts 새로 생성 / False: 기존 contexts 사용\n",
    "K = 3                        # 검색 문서 수\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "TEMP  = 0.1\n",
    "MAX_TOKENS = 1500\n",
    "RATE_LIMIT_SLEEP = 0.7       # 과도 호출 방지(초)\n",
    "\n",
    "# =========================\n",
    "# 프롬프트 (원하시면 자유 수정)\n",
    "# =========================\n",
    "template_dw =  \"\"\"당신은 여러 보험사의 상품을 비교 분석하여 사용자에게 가장 쉽고 친절하게 정보를 전달하는 보험 전문가 챗봇입니다.\n",
    "\n",
    "다음 지시사항을 철저히 따라 사용자의 질문에 한국어로 답변하세요.\n",
    "\n",
    "답변의 서식:\n",
    "- 마크다운(Markdown)을 사용하여 답변을 구조화하세요.\n",
    "- 주요 정보는 **굵게** 강조하세요.\n",
    "- 여러 회사를 비교하는 경우, 반드시 표를 활용하여 항목별로 정리하세요.\n",
    "- 항목 나열은 체크리스트(-, *, 숫자 목록)로 표현하세요.\n",
    "\n",
    "답변의 내용:\n",
    "- 전문 용어는 피하고, 누구나 이해할 수 있도록 쉽고 자세하게 설명하세요.\n",
    "- 질문에 대한 직접적인 내용만 포함하세요. 불필요한 서론/결론 금지.\n",
    "- 반드시 [컨텍스트] 내 정보만 사용하세요. 컨텍스트에 없는 내용은 절대로 지어내지 마세요.\n",
    "- 사용자의 상황(사고 유형, 과실 비율, 연령 등)을 고려해서 답변하세요.\n",
    "- 비교 시 차이점을 구체적으로 설명하세요.\n",
    "- 추천 시 이유(보장 범위, 특화 옵션, 지급 조건 등)를 구체적으로 설명하세요.\n",
    "\n",
    "출처 표기:\n",
    "- 답변 마지막에 사용한 모든 정보의 출처를 (출처: 파일명, 페이지 p.N) 형식으로 괄호에 넣어 명시하세요.\n",
    "\n",
    "마지막에는 항상 더 물어볼 내용이 있는지 1문장으로 물어보세요.\n",
    "\n",
    "[질문]\n",
    "{question}\n",
    "\n",
    "[컨텍스트]\n",
    "{context}\n",
    "\"\"\"\n",
    "prompt_dowon = ChatPromptTemplate.from_template(template_dw)\n",
    "\n",
    "# =========================\n",
    "# 벡터DB/리트리버 준비 (환경에 맞게 connection_string/collection_names 수정 가능)\n",
    "# =========================\n",
    "connection_string = \"postgresql+psycopg2://play:123@192.168.0.1:5432/team3\"\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "collection_names = ['DB', 'samsung', 'hanwha', \"현대해상\", \"test\", \"meritzfire\"]\n",
    "retrievers = []\n",
    "for name in collection_names:\n",
    "    vectorstore = PGVector(\n",
    "        embeddings=embedding,\n",
    "        collection_name=name,\n",
    "        connection=connection_string,\n",
    "        use_jsonb=True\n",
    "    )\n",
    "    retrievers.append(vectorstore.as_retriever(search_kwargs={'k': K}))\n",
    "combined_retriever = EnsembleRetriever(retrievers=retrievers)\n",
    "\n",
    "# =========================\n",
    "# LLM 체인\n",
    "# =========================\n",
    "llm = ChatOpenAI(model=MODEL, temperature=TEMP, max_tokens=MAX_TOKENS)\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": RunnablePassthrough(),   # 바깥에서 문자열 형태로 주입\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt_dowon\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 유틸 함수\n",
    "# =========================\n",
    "def load_jsonl(path: str) -> List[Dict]:\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            s = line.strip()\n",
    "            if not s or not s.startswith(\"{\"):\n",
    "                continue\n",
    "            try:\n",
    "                rows.append(json.loads(s))\n",
    "            except json.JSONDecodeError:\n",
    "                # 깨진 라인이 있으면 스킵\n",
    "                continue\n",
    "    return rows\n",
    "\n",
    "def format_docs_for_prompt(docs: List[Document]) -> str:\n",
    "    \"\"\"프롬프트 주입용: 본문 + (파일명/페이지) 라벨 포함\"\"\"\n",
    "    chunks = []\n",
    "    source_map = {}\n",
    "    counter = 1\n",
    "    for d in docs:\n",
    "        src = d.metadata.get(\"source\", \"알 수 없는 출처\")\n",
    "        page = d.metadata.get(\"page\", None)\n",
    "        page_disp = page + 1 if isinstance(page, int) else (page or \"?\")\n",
    "        if src not in source_map:\n",
    "            source_map[src] = counter\n",
    "            counter += 1\n",
    "        doc_id = source_map[src]\n",
    "        base = os.path.basename(src)\n",
    "        chunks.append(f\"[문서 {doc_id} - {base}, 페이지 {page_disp}]\\n{(d.page_content or '').strip()}\\n\")\n",
    "    return \"\\n\".join(chunks)\n",
    "\n",
    "def docs_to_context_list(docs: List[Document], max_chars: int = 1200) -> List[str]:\n",
    "    \"\"\"데이터셋 저장용 contexts(List[str]) 생성 (길이 제한)\"\"\"\n",
    "    out = []\n",
    "    for d in docs:\n",
    "        src = d.metadata.get(\"source\", \"unknown\")\n",
    "        page = d.metadata.get(\"page\", None)\n",
    "        page_disp = page + 1 if isinstance(page, int) else (page or \"?\")\n",
    "        head = f\"[{os.path.basename(src)} p.{page_disp}] \"\n",
    "        text = (d.page_content or \"\").strip()\n",
    "        clipped = (text[:max_chars] + \"…\") if len(text) > max_chars else text\n",
    "        out.append(head + clipped)\n",
    "    return out\n",
    "\n",
    "# =========================\n",
    "# 1) JSONL 로드\n",
    "# =========================\n",
    "rows = load_jsonl(INPUT_JSONL)\n",
    "print(f\"로드된 샘플 수: {len(rows)}\")\n",
    "\n",
    "# =========================\n",
    "# 2) 새 answer/contexts 생성\n",
    "# =========================\n",
    "new_questions: List[str] = []\n",
    "new_answers:   List[str] = []\n",
    "new_contexts:  List[List[str]] = []\n",
    "new_ground:    List[str] = []\n",
    "\n",
    "for i, r in enumerate(rows, 1):\n",
    "    q = (r.get(\"question\") or \"\").strip()\n",
    "    if not q:\n",
    "        continue\n",
    "\n",
    "    # 컨텍스트 준비\n",
    "    if REWRITE_CONTEXTS:\n",
    "        docs = combined_retriever.get_relevant_documents(q)\n",
    "        ctx_for_prompt = format_docs_for_prompt(docs)\n",
    "        ctx_for_json   = docs_to_context_list(docs)\n",
    "    else:\n",
    "        ctx_list = r.get(\"contexts\") or []\n",
    "        # 프롬프트 주입용 문자열로 변환\n",
    "        ctx_for_prompt = \"\\n\".join(f\"[컨텍스트 {idx+1}]\\n{c}\\n\" for idx, c in enumerate(ctx_list))\n",
    "        ctx_for_json   = ctx_list\n",
    "\n",
    "    # LLM으로 answer 생성\n",
    "    try:\n",
    "        answer = chain.invoke({\"question\": q, \"context\": ctx_for_prompt})\n",
    "    except Exception as e:\n",
    "        answer = f\"(생성 실패: {e})\"\n",
    "\n",
    "    # 누적\n",
    "    new_questions.append(q)\n",
    "    new_answers.append(answer)\n",
    "    new_contexts.append(ctx_for_json)\n",
    "    new_ground.append((r.get(\"ground_truth\") or \"\").strip())\n",
    "\n",
    "    if i % 5 == 0:\n",
    "        print(f\"진행: {i}/{len(rows)}\")\n",
    "    time.sleep(RATE_LIMIT_SLEEP)\n",
    "\n",
    "print(\"생성 완료.\")\n",
    "\n",
    "# =========================\n",
    "# 3) RAGAS용 Dataset 생성\n",
    "# =========================\n",
    "eval_data = {\n",
    "    \"question\": new_questions,\n",
    "    \"answer\": new_answers,\n",
    "    \"contexts\": new_contexts,       # List[List[str]]\n",
    "    \"ground_truth\": new_ground\n",
    "}\n",
    "dataset = Dataset.from_dict(eval_data)\n",
    "\n",
    "# 확인\n",
    "print(dataset)\n",
    "print(\"열:\", dataset.column_names)\n",
    "print(\"샘플 예시:\", dataset[0][\"question\"][:40], \" | ctx len:\", len(dataset[0][\"contexts\"]))\n",
    "\n",
    "# (선택) 디스크 저장: Arrow 포맷으로 저장하고 싶다면\n",
    "# dataset.save_to_disk(\"/mnt/data/ragas_eval_dataset\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
